{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviewsClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All lower case\n",
    "#Remove numbers\n",
    "#Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "#Remove whitespace\n",
    "\n",
    "# for i in range(len(reviews)):\n",
    "#     reviews[\"reviews\"][i] = reviews[\"reviews\"][i].lower()\n",
    "#     reviews[\"reviews\"][i] = re.sub(r'\\d+', '', reviews[\"reviews\"][i])\n",
    "#     reviews[\"reviews\"][i] = reviews[\"reviews\"][i].translate(translator)\n",
    "#     reviews[\"reviews\"][i] = \" \".join(reviews[\"reviews\"][i].split())\n",
    "# #print(reviews)\n",
    "# reviews.to_csv(\"reviewsClean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reviews[\"reviews\"][0].split()))\n",
    "print(round(sum([len(i.split())for i in reviews[\"reviews\"]])/len(reviews[\"reviews\"])))\n",
    "\n",
    "max_vocab_length = 10000\n",
    "max_length = 10469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length,\n",
    "                                    pad_to_max_tokens=True)\n",
    "\n",
    "text_vectorizer.adapt(reviews[\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random_sentence = random.choice(reviews[\"reviews\"])\n",
    "#print(random_sentence)\n",
    "#print(text_vectorizer(random_sentence))\n",
    "\n",
    "#words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "#top_5_words = words_in_vocab[:5]\n",
    "#bottom_5_words = words_in_vocab[-5:]\n",
    "#print(top_5_words,bottom_5_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                             output_dim=64,\n",
    "                             input_length=max_length)\n",
    "\n",
    "#print(embedding(text_vectorizer(random_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pooling_layer = layers.GlobalAveragePooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = text_vectorizer(reviews[\"reviews\"])\n",
    "x = embedding(x)\n",
    "x = pooling_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors=10)\n",
    "nn.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "directory = \"saved_model\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Define the file path\n",
    "file_path = os.path.join(directory, \"nearest_neighbors.joblib\")\n",
    "joblib.dump(nn, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "if  os.path.exists(directory):\n",
    "    nn = joblib.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = embedding(text_vectorizer(\"family\"))\n",
    "neighbours = nn.kneighbors(text, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in neighbours[0]:\n",
    "    movie_id = reviews.iloc[index][\"imdb_id\"]\n",
    "    print(f\"Movie ID: {movie_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
